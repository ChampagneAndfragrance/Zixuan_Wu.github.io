---
title: Diffusion-reinforcement learning hierarchical motion planning in adversarial
  multi-agent games
authors:
- admin
- Sean Ye
- Manisha Natarajan
- Matthew C Gombolay
date: 2024-05-15
publishDate: '2024-01-01'
publication_types:
- manuscript
publication: '*arXiv preprint arXiv:2403.10794*'
abstract: Reinforcement Learning- (RL-)based motion planning has recently shown the
  potential to outperform traditional approaches from autonomous navigation to robot
  manipulation. In this work, we focus on a motion planning task for an evasive target
  in a partially observable multi-agent adversarial pursuit-evasion games (PEG). These
  pursuit-evasion problems are relevant to various applications, such as search and
  rescue operations and surveillance robots, where robots must effectively plan their
  actions to gather intelligence or accomplish mission tasks while avoiding detection
  or capture themselves. We propose a hierarchical architecture that integrates a
  high-level diffusion model to plan global paths responsive to environment data while
  a low-level RL algorithm reasons about evasive versus global path-following behavior.
  Our approach outperforms baselines by 51.2% by leveraging the diffusion model to
  guide the RL algorithm for more efficient exploration and improves the explanability
  and predictability.

tags:
  - Generative Models, Motion Planning, Multi-agent
# Display this page in the Featured widget?
featured: true

url_pdf: 'https://arxiv.org/pdf/2403.10794'
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: 'https://arxiv.org/abs/2403.10794'
url_video: ''
---
